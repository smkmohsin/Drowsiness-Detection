{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Drowsiness-Detection",
      "provenance": [],
      "mount_file_id": "147WgfwALGXE3X3-Wv-AJqyEbWlbKvgAl",
      "authorship_tag": "ABX9TyPDfDfLtt3CugLjodBp+MAi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smkmohsin/Drowsiness-Detection/blob/main/Drowsiness_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dlib\n",
        "!pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRpxIleajZT3",
        "outputId": "02ed9cee-a4ea-4f43-fc94-f2617c2c46b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (19.18.0)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.5)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 24 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=df258545fc218e6579a774ac2b55089767a449560e76ace24fdee6b6e3a0b86d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ePx6AL6Aidua"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import face_recognition as fr\n",
        "import dlib\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Face Matching**\n",
        "\n",
        "First, we get the location of where exactly the face is in the image using face_location() method(which gets the outline of the face) on the RGB image. Then face encodings(markings of eyes, nose, mouth, jaws which remain the same for different images of the same person) are taken using face_encodings() function which returns a list containing 128 measurements. Both these two steps are followed for the original and test image. Then a comparison between these two returned lists is done by the function compare_faces() which returns a list of boolean values(True or False). The face distance function gets the value of that by how much the two images differ. The lower the distance the better the matching and vice versa."
      ],
      "metadata": {
        "id": "bNapAx2QvF0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With same image\n",
        "imgMoh = fr.load_image_file('/content/drive/MyDrive/Almabetter/Module 7/Capstone Project/ImagesAttendance/Mohsin.PNG')\n",
        "Test1 = imgMoh\n",
        "fLoc = fr.face_locations(imgMoh)[0]\n",
        "encodeMoh = fr.face_encodings(imgMoh)[0]\n",
        "fLocTest = fr.face_locations(Test1)[0]\n",
        "encTest = fr.face_encodings(Test1)[0]\n",
        "result1 = fr.compare_faces([encodeMoh],encTest)\n",
        "faceDist1 = fr.face_distance([encodeMoh],encTest)\n",
        "print(result1,faceDist1)\n",
        "\n",
        "# With different image\n",
        "imgMoh = fr.load_image_file('/content/drive/MyDrive/Almabetter/Module 7/Capstone Project/ImagesAttendance/Mohsin.PNG')\n",
        "Test2 = fr.load_image_file('/content/drive/MyDrive/Almabetter/Module 7/Capstone Project/ImagesAttendance/Chris.jpg')\n",
        "fLoc = fr.face_locations(imgMoh)[0]\n",
        "encodeMoh = fr.face_encodings(imgMoh)[0]\n",
        "fLocTest = fr.face_locations(Test2)[0]\n",
        "encTest = fr.face_encodings(Test2)[0]\n",
        "result2 = fr.compare_faces([encodeMoh],encTest)\n",
        "faceDist2 = fr.face_distance([encodeMoh],encTest)\n",
        "print(result2,faceDist2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzHeFsZcis6b",
        "outputId": "55b52fe6-e5be-49f1-e2d4-9cc0ba97febb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True] [0.]\n",
            "[False] [1.02709267]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Face Attendance System \n",
        "\n",
        "Now we are ready to build a realtime face attendance system wherein webcam captured frames will be matched against the existing database images and if the match is found then it’ll store it in a CSV file called ‘Attendance Register’ along with name and time of capture. Only once the file will store the matched image’s details, if the same image is received again then it’ll not update.\n",
        "\n",
        "Path setting to the directory containing the image database. Read each image and the images array. Append the filenames into a list called Names and remove the extension."
      ],
      "metadata": {
        "id": "M4dOFW7DwcGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pathlib = '/content/drive/MyDrive/Almabetter/Module 7/Capstone Project/ImagesAttendance'\n",
        "images = []\n",
        "Names = []\n",
        "myList = os.listdir(pathlib)\n",
        "print(myList)\n",
        "for cl in myList:\n",
        "    currImg = cv2.imread(f'{pathlib}/{cl}')\n",
        "    images.append(currImg)\n",
        "    Names.append(os.path.splitext(cl)[0])\n",
        "print(Names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QNHkFEkrXYL",
        "outputId": "d0ed4e99-f024-4ea7-d4bc-3cbb34b732cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Chris.jpg', 'Mohsin.PNG']\n",
            "['Chris', 'Mohsin']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding face encodings of images in the database and keeping them in a list to use later with incoming frames. "
      ],
      "metadata": {
        "id": "7tFSxXFxzC3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DbEncodings(images):\n",
        "    encList = []\n",
        "    for image in images:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        enc = fr.face_encodings(image)[0]\n",
        "        encList.append(enc)\n",
        "    return encodeList"
      ],
      "metadata": {
        "id": "ndMcZSBRwfqJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capturing video frames\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Iterating through frames\n",
        "\n",
        "while True:\n",
        "    _, img = cap.read()\n",
        "    # image = cv2.resize(img,(0,0),None,0.25,0.25)\n",
        "    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "# The same process is followed by the first detection face location then getting the face encoding values.\n",
        "\n",
        "    facesInFrame = fr.face_locations(image)\n",
        "    encodesInFrame = fr.face_encodings(image,facesInFrame)\n",
        "\n",
        "# Now the incoming images are tested against the previously-stored encodings. Then the face distance is also computed. Lastly, we call the Attendance function along with the person name who is identified.\n",
        "\n",
        "for encodeFace,faceLoc in zip(encodesInFrame,facesInFrame):\n",
        "        matchList = fr.compare_faces(encodeKnown,encFace)\n",
        "        faceDist = fr.face_distance(encodeKnown,encFace)\n",
        "        match = np.argmin(faceDist)\n",
        "        if matchList[match]:\n",
        "            name = Names[match].upper()\n",
        "            Attendance(name)\n",
        "\n",
        "\n",
        "#Reading from attendance file, Storing data(Name and Time of entry) if previously not stored.\n",
        "\n",
        "def Attendance(name):\n",
        "    with open('Attendance_Register.csv','r+') as f:\n",
        "        DataList = f.readlines()\n",
        "        names = []\n",
        "        for data in DataList:\n",
        "            ent = data.split(',')\n",
        "            names.append(ent[0])\n",
        "        if name not in names:\n",
        "            curr = datetime.now()\n",
        "            dt = curr.strftime('%H:%M:%S')\n",
        "            f.writelines(f'\\n{name},{dt}')\n",
        "encodeKnown = DbEncodings(images)\n",
        "print('Encoding Complete')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "pCm_VlRRzpXr",
        "outputId": "90a7d01a-ced3-459f-cd20-5b802f2dcb4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cb19a821067a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# image = cv2.resize(img,(0,0),None,0.25,0.25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# The same process is followed by the first detection face location then getting the face encoding values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EIBRBF8Xz1QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cADcJI2N0K2G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}